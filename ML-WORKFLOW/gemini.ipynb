{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a6821170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "# Updated import for memory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_ollama import ChatOllama\n",
    "from pydantic import BaseModel, Field\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9797fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google import genai\n",
    "# genai.models\n",
    "# client = genai.Client(api_key=\"AIzaSyDrPY-M6t2BUQ32WIoKOpxfd2izJkxaJPk\")\n",
    "\n",
    "# model = genai.GenerativeModel(model_name=\"gemini-pro\")  # or gemini-1.5-pro / flash\n",
    "# response = model.generate_content(\"Tell me a joke about AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ed73e1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the AI cross the road?\n",
      "\n",
      "To prove to the chicken that it wasn't a simulation!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai  # âœ… correct import\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDrPY-M6t2BUQ32WIoKOpxfd2izJkxaJPk\")\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")  # or gemini-1.5-pro / flash\n",
    "response = model.generate_content(\"Tell me a joke about AI.\")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "98154442",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2:1b\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dfb6fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionGeneratorInput(BaseModel):\n",
    "    topic: str = Field(description=\"Topic for the question\")\n",
    "    difficulty: str = Field(description=\"Difficulty level: easy, medium, or hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0386c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationInput(BaseModel):\n",
    "    answer: str = Field(description=\"User's answer to evaluate\")\n",
    "    question: str = Field(description=\"The question that was asked\")\n",
    "    difficulty: str = Field(description=\"Difficulty level of the question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4a7ed6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionSelectorInput(BaseModel):\n",
    "    current_difficulty: str = Field(description=\"Current difficulty level\")\n",
    "    eval_score: int = Field(description=\"Current evaluation score\")\n",
    "    question_count: int = Field(description=\"Number of questions asked so far\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "db281542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportGeneratorInput(BaseModel):\n",
    "    questions : List[str] = Field(description=\"List of all user answers\")\n",
    "    \n",
    "    answers: List[str] = Field(description=\"List of all user answers\")\n",
    "    \n",
    "    eval_scores: List[int] = Field(description=\"List of evaluation scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dadc3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Question_generator(input_data: QuestionGeneratorInput,additional_prompt = \"\") -> str:\n",
    "    \"\"\"Generate a question based on the topic and difficulty level.\"\"\"\n",
    "    prompt = f\"You are a teacher with expertise in {input_data.topic}. Ask a strictly theoretical and short {input_data.difficulty} level question.\" + additional_prompt\n",
    "    return model.generate_content(prompt).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "82b8598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answer(input_data: EvaluationInput) -> Dict[str, Any]:\n",
    "\t\"\"\"you are a highly educated expert and your job is to perform strict evaluation of the answer based on the given question\"\"\"\n",
    "\t# Simple evaluation logic - can be made more sophisticated\n",
    "\tprompt = f\"\"\"you are a highly educated expert and your job is to perform strict evaluation of the answer based on the given question\"{input_data.question}\" \n",
    "\tAnd the answer: \"{input_data.answer}\"\n",
    "\tEvaluate this {input_data.difficulty} level answer on a scale of 0-10.\n",
    "\tmake sure to respond with a number between 0 and 10.\"\"\"\n",
    "\tscore = model.generate_content(prompt).text\n",
    "\ttry:\n",
    "\t\tmatch = re.search(r'\\d+', score.content)\n",
    "\t\tif match:\n",
    "\t\t\t\treturn int(match.group())\n",
    "\texcept:\n",
    "\t\treturn 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1c6b56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answer(input_data: EvaluationInput) -> Dict[str, Any]:\n",
    "\t\"\"\"you are a highly educated expert and your job is to perform strict evaluation of the answer based on the given question\"\"\"\n",
    "\t# Simple evaluation logic - can be made more sophisticated\n",
    "\tprompt = f\"\"\"you are a highly educated expert and your job is to perform strict evaluation of the answer based on the given question\"{input_data.question}\" \n",
    "\tAnd the answer: \"{input_data.answer}\"\n",
    "\tEvaluate this {input_data.difficulty} level answer on a scale of 0-10.\n",
    "\tmake sure to respond with a number between 0 and 10.\"\"\"\n",
    "\tscore = model.generate_content(prompt).text\n",
    "\t# try:\n",
    "\t# \tmatch = re.search(r'\\d+', score.content)\n",
    "\t# \tif match:\n",
    "\t# \t\t\treturn int(match.group())\n",
    "\t# except:\n",
    "\t# \treturn 5\n",
    "\treturn score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f73dc309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input_da = EvaluationInput(\n",
    "# #     answer = \"continuous collection of items in an index based array, a list in python can have multiple data types\",\n",
    "# #     question = \"what is list in python\",\n",
    "# #     difficulty= \"easy\"\n",
    "    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0bdc9930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(evaluate_answer(input_da))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0ee48ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_next_question(input_data: QuestionSelectorInput) -> Dict[str, Any]:\n",
    "    \"\"\"Choose the next question difficulty based on performance.\"\"\"\n",
    "    curr_type = input_data.current_difficulty\n",
    "    eval_score = input_data.eval_score\n",
    "    question_count = input_data.question_count\n",
    "    \n",
    "    if curr_type == \"easy\" and eval_score >= 5:\n",
    "        new_type = \"medium\"\n",
    "    elif curr_type == \"medium\":\n",
    "        if eval_score >= 8:\n",
    "            new_type = \"hard\"\n",
    "        elif eval_score < 5:\n",
    "            new_type = \"easy\"\n",
    "        else:\n",
    "            new_type = \"medium\"\n",
    "    elif curr_type == \"hard\" and eval_score < 7:\n",
    "        new_type = \"medium\"\n",
    "    else:\n",
    "        new_type = curr_type\n",
    "\n",
    "    should_continue = question_count < 6\n",
    "    \n",
    "    return {\n",
    "        \"new_difficulty\": new_type,\n",
    "        \"should_continue\": should_continue\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b44c9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_final_report(input_data: ReportGeneratorInput) -> str:\n",
    "#     \"\"\"Generate a final report of the user's performance.\"\"\"\n",
    "#     prompt = f\"\"\"Based on these answers and scores, write a short evaluation highlighting strengths, weaknesses, and areas for improvement:\n",
    "#     - Average score: {sum(input_data.eval_scores) / len(input_data.eval_scores) if input_data.eval_scores else 0}\n",
    "#     \"\"\"\n",
    "#     return model.generate_content(prompt).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ab4354a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_report(input_data : ReportGeneratorInput) -> str:\n",
    "\t\"\"\"Generate a final report of the user's performance.\"\"\"\n",
    "\tzipped_lists = zip(input_data.questions, input_data.answers, input_data.eval_scores) \n",
    "\tnew_lists = [list(group) for group in zipped_lists]\n",
    "\tprompt = f\"You are highly experienced in evaluation and you have this list : {new_lists} which contains list of [questions,answers,score], you have to create a short report evaluating the student's skills and in . give response in this json format : \" + '''\n",
    "{\n",
    "  \"qalist\": [\n",
    "    {\n",
    "      \"question\": \"\",\n",
    "      \"answer\": \"\",\n",
    "      \"score\": \n",
    "    },\n",
    "  ],\n",
    "  \"analysisReport\": \"\",\n",
    "  \"weaknesses\": \"Historical Dates\"\n",
    "}\n",
    "\n",
    "'''\n",
    "\treturn model.generate_content(prompt).text\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0f5e31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_report(input_data : ReportGeneratorInput) -> str:\n",
    "\t\"\"\"Generate a final report of the user's performance.\"\"\"\n",
    "\tzipped_lists = zip(input_data.questions, input_data.answers, input_data.eval_scores) \n",
    "\tnew_lists = [list(group) for group in zipped_lists]\n",
    "\tprompt = f\"You are highly experienced in evaluation and you have this list : {new_lists} which contains list of [questions,answers,score], you have to create a short report evaluating the student's skills and in . give response in this list format : \" + '''\n",
    "{\n",
    "  \"qalist\": [\n",
    "    {\n",
    "      \"question\": \"\",\n",
    "      \"answer\": \"\",\n",
    "      \"score\": \n",
    "    },\n",
    "  ],\n",
    "  \"analysisReport\": \"\",\n",
    "  \"weaknesses\": \"Historical Dates\"\n",
    "}\n",
    "\n",
    "'''\n",
    "\treturn model.generate_content(prompt).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d1832032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['topic', 'difficulty'])\n"
     ]
    }
   ],
   "source": [
    "print(QuestionGeneratorInput.model_fields.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "25b0cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "scores = []\n",
    "\n",
    "difficulty = \"easy\"\n",
    "flag = 1\n",
    "while True:\n",
    "\tinput_data_q = QuestionGeneratorInput(\n",
    "\ttopic = \"python\",\n",
    "\tdifficulty = difficulty        \n",
    "\t)\n",
    "\n",
    "\t\n",
    "\twhile True:\n",
    "\t\tquestion = Question_generator(input_data_q)\n",
    "\t\tif question not in questions:\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tquestion = Question_generator(input_data_q,additional_prompt=\"Generate a new and different question\")\n",
    "\n",
    "\tuserMessage = input(f\"answer the following : {question}\")\n",
    "\n",
    "\tinput_data_e=EvaluationInput(\n",
    "\t\t\t\t\tanswer=userMessage,\n",
    "\t\t\t\t\tquestion=question,\n",
    "\t\t\t\t\tdifficulty=difficulty\n",
    "\t\t\t\t)\n",
    "\t\n",
    "\tscore = int(evaluate_answer(input_data_e))\n",
    "\tquestions.append(question)\n",
    "\tanswers.append(userMessage)\n",
    "\tscores.append(score)\n",
    "\n",
    "\tinput_data_qs = QuestionSelectorInput(\n",
    "\t\tcurrent_difficulty= difficulty,\n",
    "\t\teval_score=score,\n",
    "\t\tquestion_count=flag\n",
    "\t)\n",
    "\n",
    "\tnew_difficulty,should_continue = choose_next_question(input_data_qs)\n",
    "\n",
    "\tif not should_continue or flag>3:\n",
    "\t\tinput_data_r = ReportGeneratorInput(\n",
    "\t\t\tquestions=questions,\n",
    "\t\t\tanswers=answers,\n",
    "\t\t\teval_scores=scores\n",
    "\t\t)\n",
    "\t\treport = generate_final_report(input_data_r)\n",
    "\t\tbreak\n",
    "\telse:\n",
    "\t\tdifficulty = new_difficulty\n",
    "\t\tflag +=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "32475cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"qalist\": [\n",
      "    {\n",
      "      \"question\": \"Alright class, let's start with a quick, purely theoretical question:\\n\\n**True or False: In Python, a variable's data type is explicitly declared when the variable is created.**\\n\",\n",
      "      \"answer\": \"no\",\n",
      "      \"score\": 10\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"Alright class, let's try a quick thought experiment.\\n\\n**Question:** In Python, conceptually explain the difference between \\\"mutable\\\" and \\\"immutable\\\" data types, and give one example of each. Don't write any code, just the definitions and examples in plain English.\\n\",\n",
      "      \"answer\": \"mutable is datatype that can be edited and modified\",\n",
      "      \"score\": 5\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"Okay, class, here's a quick thought experiment for you:\\n\\nImagine you're designing a system that relies on Python's dictionaries. Ignoring memory constraints, what are the *theoretical* limits on the number of key-value pairs a single dictionary could hold, considering the underlying data structures and hashing mechanisms at play? Just a brief explanation of the limiting factors is sufficient.\\n\",\n",
      "      \"answer\": \"i dont know this\",\n",
      "      \"score\": 0\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"Alright class, let's try a slightly trickier theoretical concept.\\n\\n**Question:**\\n\\nIn Python, if you have a variable assigned to a mutable object (like a list), and then assign that variable to another variable, do both variables now point to the *same* memory location, or do they create separate copies of the object's data? Explain your answer briefly.\\n\",\n",
      "      \"answer\": \"seperate copies\",\n",
      "      \"score\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"analysisReport\": \"The student demonstrates a basic understanding of Python fundamentals, correctly identifying that data types are not explicitly declared (True/False question). Their understanding of mutability is partially correct but lacks the nuance of explaining that changes affect the original variable. They struggle with more complex concepts relating to memory management (dictionary limits) and object references. More in-depth explanation for each question is needed.\",\n",
      "  \"weaknesses\": \"Memory Management, Object References, Mutability nuance, Hashing Mechanisms\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "84800835",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json_from_text(final_text):\n",
    "    pattern = r\"```json\\n([\\s\\S]*?)```\"\n",
    "    match = re.search(pattern, final_text, re.MULTILINE)\n",
    "    if match:\n",
    "        return json.loads(match.group(1))\n",
    "    else:\n",
    "        raise ValueError(\"No JSON block found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cedf8c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qalist': [{'question': \"Alright class, let's start with a quick, purely theoretical question:\\n\\n**True or False: In Python, a variable's data type is explicitly declared when the variable is created.**\\n\",\n",
       "   'answer': 'no',\n",
       "   'score': 10},\n",
       "  {'question': 'Alright class, let\\'s try a quick thought experiment.\\n\\n**Question:** In Python, conceptually explain the difference between \"mutable\" and \"immutable\" data types, and give one example of each. Don\\'t write any code, just the definitions and examples in plain English.\\n',\n",
       "   'answer': 'mutable is datatype that can be edited and modified',\n",
       "   'score': 5},\n",
       "  {'question': \"Okay, class, here's a quick thought experiment for you:\\n\\nImagine you're designing a system that relies on Python's dictionaries. Ignoring memory constraints, what are the *theoretical* limits on the number of key-value pairs a single dictionary could hold, considering the underlying data structures and hashing mechanisms at play? Just a brief explanation of the limiting factors is sufficient.\\n\",\n",
       "   'answer': 'i dont know this',\n",
       "   'score': 0},\n",
       "  {'question': \"Alright class, let's try a slightly trickier theoretical concept.\\n\\n**Question:**\\n\\nIn Python, if you have a variable assigned to a mutable object (like a list), and then assign that variable to another variable, do both variables now point to the *same* memory location, or do they create separate copies of the object's data? Explain your answer briefly.\\n\",\n",
       "   'answer': 'seperate copies',\n",
       "   'score': 0}],\n",
       " 'analysisReport': 'The student demonstrates a basic understanding of Python fundamentals, correctly identifying that data types are not explicitly declared (True/False question). Their understanding of mutability is partially correct but lacks the nuance of explaining that changes affect the original variable. They struggle with more complex concepts relating to memory management (dictionary limits) and object references. More in-depth explanation for each question is needed.',\n",
       " 'weaknesses': 'Memory Management, Object References, Mutability nuance, Hashing Mechanisms'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_json_from_text(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245bdd51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
